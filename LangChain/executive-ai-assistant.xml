<?xml version="1.0"?>
<Container version="2">
  <Name>Executive-AI-Assistant</Name>
  <Repository>ghcr.io/ryan-haver/executive-ai-assistant:latest</Repository>
  <Registry>https://github.com/ryan-haver/executive-ai-assistant/pkgs/container/executive-ai-assistant</Registry>
  <Network>bridge</Network>
  <MyIP/>
  <Shell>bash</Shell>
  <Privileged>false</Privileged>
  <Support>https://github.com/ryan-haver/executive-ai-assistant</Support>
  <Project>https://github.com/langchain-ai/executive-ai-assistant</Project>
  <Overview>Executive AI Assistant - Your AI-powered email management assistant that drafts professional responses using LangChain and multiple LLM providers.

This intelligent assistant monitors your Gmail inbox, triages emails, drafts professional responses, and helps you manage your communications efficiently using state-of-the-art AI models.

**KEY FEATURES:**
- üìß Automated email monitoring and triage
- ‚úçÔ∏è AI-powered draft response generation
- üîÑ Multi-LLM support (Ollama, OpenAI, Anthropic)
- üéØ Context-aware response generation
- üìÖ Meeting scheduling assistance
- üîç Intelligent email categorization
- üíæ Persistent conversation history
- üîí Secure OAuth2 Gmail integration

**SUPPORTED LLM PROVIDERS:**
- **Ollama** - Free, local AI models (llama3.2, llama3.1, etc.)
- **OpenAI** - GPT-4o, GPT-4o-mini, O1
- **Anthropic** - Claude 3.5 Sonnet, Claude 3 Haiku
- **Hybrid Mode** - Ollama with cloud fallback (recommended)
- **Auto Mode** - Automatically detect available providers

**IMPORTANT - GMAIL OAUTH SETUP (REQUIRED):**

This container REQUIRES Gmail OAuth credentials to function. You have TWO OPTIONS for setup:

**üéØ OPTION 1: WEB-BASED SETUP (RECOMMENDED - EASIEST)**

NEW! Use the built-in Setup UI for a streamlined 3-5 minute setup process:

1. Start the container (it will run in degraded mode without credentials)
2. Access the Setup UI at: **http://YOUR-SERVER-IP:2025/setup**
3. Follow the on-screen instructions:
   - Download your client_secret.json from Google Cloud Console (see steps below)
   - Upload the file via drag-and-drop interface
   - Click "Connect to Gmail" to authorize
   - Complete OAuth flow in browser
   - Done! Container automatically starts processing emails

The Setup UI handles all credential storage and validation automatically. No terminal commands required!

**üìã OPTION 2: MANUAL SETUP (ADVANCED)**

If you prefer manual setup or need to troubleshoot, follow the detailed steps below to generate and base64-encode your credentials.

---

**OAUTH PREREQUISITES (Required for Both Options):**

Before using either setup method, you must create a Google Cloud Project and OAuth credentials:

**Step 1: Create Google Cloud Project**
1. Go to: https://console.cloud.google.com/
2. Click the project selector dropdown in the **upper left** (shows current project name or "Select a project")
3. Click "NEW PROJECT" button in the dialog
4. Enter project name: "Executive AI Assistant"
5. (Optional) Edit the project ID if desired
6. Click "CREATE"
7. Wait for project creation (notification appears in top-right)
8. **Important**: Select your new project from the dropdown to activate it

**Step 2: Enable Gmail API**
1. In your project, go to "APIs &amp; Services" ‚Üí "Enabled APIs &amp; services"
2. Click "+ ENABLE APIS AND SERVICES" (blue button at top)
3. Search for "Gmail API"
4. Click on "Gmail API" in results
5. Click "ENABLE" button
6. Wait for activation (30-60 seconds)

**Step 3: Configure OAuth Consent Screen**
1. Go to "APIs &amp; Services" ‚Üí "OAuth consent screen"
2. Choose "User type":
   - **External** (for personal Gmail accounts - most users)
   - **Internal** (only for Google Workspace organizations)
3. Click "CREATE"
4. Fill in required app information:
   - App name: "Executive AI Assistant"
   - User support email: Your email address
   - (Optional) App logo, privacy policy, terms of service
5. Click "SAVE AND CONTINUE"
6. Add Scopes:
   - Click "ADD OR REMOVE SCOPES"
   - Search for "Gmail API"
   - Select ".../auth/gmail.modify" scope
   - Click "UPDATE"
   - Click "SAVE AND CONTINUE"
7. Add Test Users (required for External apps):
   - Click "ADD USERS"
   - Enter your Gmail address
   - Click "ADD"
   - Click "SAVE AND CONTINUE"
8. Review summary and click "BACK TO DASHBOARD"

**Step 4: Create OAuth Client ID Credentials**
1. Go to "APIs &amp; Services" ‚Üí "Credentials"
2. Click "+ CREATE CREDENTIALS" at top
3. Select "OAuth client ID"
4. Application type: **Desktop app**
5. Name: "Executive AI Assistant Desktop Client"
6. Click "CREATE"
7. In the popup, click "DOWNLOAD JSON"
8. Save as `client_secret.json` (remember the location!)
9. Click "OK" to close the dialog

**Step 5: Generate OAuth Token**
Run this command in Unraid terminal (replace /path/to/client_secret.json):

```bash
docker run --rm -it \
  -v /path/to/client_secret.json:/app/client_secret.json \
  ghcr.io/ryan-haver/executive-ai-assistant:latest \
  python /app/scripts/setup_gmail.py
```

This will:
- Display a URL - copy it and paste in your browser
- You'll be asked to sign in to Google and authorize the app
- After authorization, copy the code from browser
- Paste it back in the terminal
- The script will save your token

**Step 6: Encode Credentials for Unraid**
After token generation, run these commands to get base64-encoded values:

```bash
# Encode client secret
base64 -w 0 /path/to/client_secret.json

# Encode token (created in Step 5)
base64 -w 0 /path/to/token.json
```

Copy these base64 strings and paste them into the "Gmail Client Secret" and "Gmail OAuth Token" fields below.

**QUICK START GUIDE:**

**Option 1: Free Local AI (Ollama)**
1. Install Ollama container from Community Apps
2. Pull a model: `docker exec ollama ollama pull llama3.2:3b`
3. Set LLM Provider to: "ollama"
4. Set Ollama Host to: "http://YOUR_UNRAID_IP:11434"
5. Configure Gmail OAuth (see above)
6. Start the container

**Option 2: Cloud AI (OpenAI)**
1. Get API key from: https://platform.openai.com/api-keys
2. Set LLM Provider to: "openai"
3. Paste your API key in "OpenAI API Key" field
4. Configure Gmail OAuth (see above)
5. Start the container

**Option 3: Hybrid Mode (Recommended)**
1. Set up both Ollama and OpenAI/Anthropic
2. Set LLM Provider to: "hybrid"
3. Container uses Ollama when available, falls back to cloud
4. Best of both worlds: free + reliable

**ACCESSING THE ASSISTANT:**
- Setup UI: http://YOUR_UNRAID_IP:2025/setup (for OAuth configuration)
- LangGraph API: http://YOUR_UNRAID_IP:2024 (main API and web interface)
- LangGraph Studio: Connect to http://YOUR_UNRAID_IP:2024
- Agent Inbox: Install separate Agent Inbox container for GUI

**FIRST-TIME SETUP:**
1. Start the container
2. Visit http://YOUR_UNRAID_IP:2025/setup in your browser
3. Upload your client_secret.json file
4. Complete the OAuth authorization flow
5. Container will automatically start processing emails

**CRON SCHEDULING:**
By default, the assistant checks for new emails every 5 minutes. You can customize this:
- Every 15 minutes: "*/15 * * * *"
- Every hour: "0 * * * *"
- 9am-5pm weekdays: "0 9-17 * * 1-5"

**TROUBLESHOOTING:**

**Container won't start / Health check failing:**
- Check logs: `docker logs executive-ai-assistant`
- Verify Gmail credentials are base64-encoded correctly
- Ensure at least one LLM provider is configured

**Gmail OAuth errors:**
- Re-run setup_gmail.py script to regenerate token
- Verify OAuth consent screen is configured
- Check that test users include your email
- Make sure Gmail API is enabled

**Ollama connection failed:**
- Verify Ollama is running: `docker ps | grep ollama`
- Test connection: `curl http://YOUR_UNRAID_IP:11434/api/tags`
- Check Ollama Host setting matches your setup
- Ensure network allows container-to-container communication

**No emails being processed:**
- Check cron logs: `docker exec executive-ai-assistant cat /var/log/eaia/cron.log`
- Verify email arrived in last X minutes (CRON_MINUTES_SINCE setting)
- Check Gmail token hasn't expired
- Review API logs for errors

**SECURITY NOTES:**
- Gmail credentials are stored in Docker volumes (not visible in Unraid GUI)
- API keys are masked in the template (not shown in plain text)
- Consider using Ollama for privacy-sensitive emails
- LangSmith tracing is optional (disabled by default)
- Keep your OAuth credentials secure and don't share them

**RESOURCE REQUIREMENTS:**
- CPU: 0.5-2.0 cores (depending on LLM usage)
- RAM: 512MB-2GB (depending on model size)
- Disk: ~1GB for container + email data
- Network: Internet access for cloud LLMs (optional for Ollama-only)

**DOCKER IMAGE DETAILS:**
- Base: python:3.12-slim
- Size: 693MB
- Services: LangGraph API (port 2024) + Setup UI (port 2025) + Cron scheduler
- Health Check: Automatic monitoring of all services

For detailed documentation, visit: https://github.com/ryan-haver/executive-ai-assistant</Overview>
  <Category>Productivity: Tools:</Category>
  <WebUI>http://[IP]:[PORT:2025]/setup</WebUI>
  <TemplateURL>https://raw.githubusercontent.com/ryan-haver/unraid-docker-templates/main/LangChain/executive-ai-assistant.xml</TemplateURL>
  <Icon>https://python.langchain.com/img/brand/wordmark.png</Icon>
  <ExtraParams>--restart=unless-stopped</ExtraParams>
  <PostArgs/>
  <CPUset/>
  <DateInstalled/>
  <DonateText/>
  <DonateLink/>
  <Description>AI-powered email assistant that monitors Gmail, triages emails, and drafts professional responses using LangChain and multiple LLM providers (Ollama, OpenAI, Anthropic).</Description>
  <Networking>
    <Mode>bridge</Mode>
    <Publish>
      <Port>
        <HostPort>2024</HostPort>
        <ContainerPort>2024</ContainerPort>
        <Protocol>tcp</Protocol>
      </Port>
    </Publish>
  </Networking>
  <Data>
    <Volume>
      <HostDir>/mnt/user/appdata/executive-ai-assistant/data</HostDir>
      <ContainerDir>/app/data</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
    <Volume>
      <HostDir>/mnt/user/appdata/executive-ai-assistant/config</HostDir>
      <ContainerDir>/app/config</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
    <Volume>
      <HostDir>/mnt/user/appdata/executive-ai-assistant/secrets</HostDir>
      <ContainerDir>/app/secrets</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
    <Volume>
      <HostDir>/mnt/user/appdata/executive-ai-assistant/logs</HostDir>
      <ContainerDir>/var/log/eaia</ContainerDir>
      <Mode>rw</Mode>
    </Volume>
  </Data>
  <Labels/>
  
  <!-- Required Configuration -->
  <Config Name="LangGraph API Port" Target="2024" Default="2024" Mode="tcp" Description="Port for LangGraph API and web interface" Type="Port" Display="always" Required="true" Mask="false">2024</Config>
  
  <Config Name="Setup UI Port" Target="2025" Default="2025" Mode="tcp" Description="Port for OAuth Setup Web UI - Use this to configure Gmail credentials via web interface instead of manual setup" Type="Port" Display="always" Required="true" Mask="false">2025</Config>
  
  <Config Name="Gmail Client Secret (Base64)" Target="GMAIL_SECRET" Default="" Mode="" Description="Base64-encoded client_secret.json from Google Cloud Console (OPTIONAL with Setup UI - can configure via web interface at port 2025)" Type="Variable" Display="always" Required="false" Mask="true"/>
  
  <Config Name="Gmail OAuth Token (Base64)" Target="GMAIL_TOKEN" Default="" Mode="" Description="Base64-encoded token.json generated by setup_gmail.py script (OPTIONAL with Setup UI - can configure via web interface at port 2025)" Type="Variable" Display="always" Required="false" Mask="true"/>
  
  <!-- LLM Provider Configuration -->
  <Config Name="LLM Provider" Target="LLM_PROVIDER" Default="auto" Mode="" Description="Choose your AI model provider: 'ollama' (free, local), 'openai' (cloud, paid), 'anthropic' (cloud, paid), 'hybrid' (ollama + cloud fallback), 'auto' (detect available)" Type="Variable" Display="always" Required="true" Mask="false">auto</Config>
  
  <Config Name="Ollama Host" Target="OLLAMA_HOST" Default="http://192.168.1.100:11434" Mode="" Description="Ollama server URL (if using Ollama). Use your Unraid IP or container name. Default port is 11434. Example: http://192.168.1.100:11434 or http://ollama:11434" Type="Variable" Display="always" Required="false" Mask="false">http://192.168.1.100:11434</Config>
  
  <Config Name="OpenAI API Key" Target="OPENAI_API_KEY" Default="" Mode="" Description="OpenAI API key (if using OpenAI). Get from: https://platform.openai.com/api-keys. Format: sk-proj-..." Type="Variable" Display="always" Required="false" Mask="true"/>
  
  <Config Name="Anthropic API Key" Target="ANTHROPIC_API_KEY" Default="" Mode="" Description="Anthropic API key (if using Claude). Get from: https://console.anthropic.com/settings/keys. Format: sk-ant-..." Type="Variable" Display="always" Required="false" Mask="true"/>
  
  <!-- Cron Configuration -->
  <Config Name="Cron Schedule" Target="CRON_SCHEDULE" Default="*/5 * * * *" Mode="" Description="How often to check for new emails (cron format). Default: */5 * * * * (every 5 minutes). Examples: */15 * * * * (every 15 min), 0 * * * * (hourly), 0 9-17 * * 1-5 (9am-5pm weekdays)" Type="Variable" Display="always" Required="false" Mask="false">*/5 * * * *</Config>
  
  <Config Name="Minutes Since Last Check" Target="CRON_MINUTES_SINCE" Default="10" Mode="" Description="How many minutes back to look for emails on each cron run. Should be at least equal to your cron frequency. Default: 10" Type="Variable" Display="always" Required="false" Mask="false">10</Config>
  
  <!-- Volume Mappings -->
  <Config Name="Data Directory" Target="/app/data" Default="/mnt/user/appdata/executive-ai-assistant/data" Mode="rw" Description="Persistent data storage for email history and state" Type="Path" Display="always" Required="true" Mask="false">/mnt/user/appdata/executive-ai-assistant/data</Config>
  
  <Config Name="Config Directory" Target="/app/config" Default="/mnt/user/appdata/executive-ai-assistant/config" Mode="rw" Description="Configuration files directory" Type="Path" Display="always" Required="true" Mask="false">/mnt/user/appdata/executive-ai-assistant/config</Config>
  
  <Config Name="Secrets Directory" Target="/app/secrets" Default="/mnt/user/appdata/executive-ai-assistant/secrets" Mode="rw" Description="Secrets storage (alternative to env vars for credentials)" Type="Path" Display="advanced" Required="false" Mask="false">/mnt/user/appdata/executive-ai-assistant/secrets</Config>
  
  <Config Name="Logs Directory" Target="/var/log/eaia" Default="/mnt/user/appdata/executive-ai-assistant/logs" Mode="rw" Description="Application and cron logs for debugging" Type="Path" Display="advanced" Required="false" Mask="false">/mnt/user/appdata/executive-ai-assistant/logs</Config>
  
  <!-- Optional Advanced Configuration -->
  <Config Name="Timezone" Target="TZ" Default="America/New_York" Mode="" Description="Container timezone (affects cron schedule). Examples: America/New_York, America/Chicago, America/Los_Angeles, Europe/London, UTC" Type="Variable" Display="advanced" Required="false" Mask="false">America/New_York</Config>
  
  <!-- Reverse Proxy Configuration -->
  <Config Name="Setup UI Base URL" Target="SETUP_UI_BASE_URL" Default="" Mode="" Description="REVERSE PROXY ONLY: Public URL for OAuth callbacks when behind reverse proxy. Example: https://assistant.example.com. Leave empty for direct access (automatically detected). Required if proxy doesn't forward X-Forwarded-* headers correctly." Type="Variable" Display="advanced" Required="false" Mask="false"/>
  
  <Config Name="CORS Allowed Origins" Target="CORS_ALLOWED_ORIGINS" Default="*" Mode="" Description="REVERSE PROXY ONLY: Comma-separated list of allowed origins for CORS. Default: * (all origins). Example: https://assistant.example.com,https://app.example.com. Use '*' for development only." Type="Variable" Display="advanced" Required="false" Mask="false">*</Config>
  
  <!-- Monitoring & Debugging -->
  <Config Name="LangSmith API Key" Target="LANGSMITH_API_KEY" Default="" Mode="" Description="Optional: LangSmith API key for tracing and debugging. Get from: https://smith.langchain.com/settings. Leave empty to disable." Type="Variable" Display="advanced" Required="false" Mask="true"/>
  
  <Config Name="LangSmith Tracing" Target="LANGCHAIN_TRACING_V2" Default="false" Mode="" Description="Enable LangSmith tracing (requires LangSmith API Key). Set to 'true' to enable, 'false' to disable." Type="Variable" Display="advanced" Required="false" Mask="false">false</Config>
  
  <Config Name="LangSmith Project" Target="LANGCHAIN_PROJECT" Default="executive-ai-assistant" Mode="" Description="LangSmith project name for organizing traces" Type="Variable" Display="advanced" Required="false" Mask="false">executive-ai-assistant</Config>
  
  <Config Name="Log Level" Target="LOG_LEVEL" Default="INFO" Mode="" Description="Logging verbosity: DEBUG (most detailed), INFO (normal), WARNING (warnings only), ERROR (errors only)" Type="Variable" Display="advanced" Required="false" Mask="false">INFO</Config>
</Container>
